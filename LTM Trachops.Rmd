---
title: "LTM Trachops"
author: "May"
date: "1/28/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Install Packages

```{r}
library(CVST)
library(jmuOutlier)
library(readxl)
library(tidyverse)
library(broom)
library(ggplot2)
library(tidyverse)
library(boot)
library(lme4)
#library(lmerTest)
library(ggpubr)
library(cowplot)
library(RColorBrewer)
library(lubridate)
```



## Import Data
```{r}
# Just read the important lines for now

Long_term_memory_experiment_01_28_21 <- read_excel("~/Dropbox/Long-term memory not shared/collected data/combined data/Long-term memory experiment_01.28.21.xlsx", 
    sheet = "all bats 1.26.21", range = "A1:L51", 
    col_types = c("text", "text", "text", 
        "date", "date", "numeric", "numeric", 
        "numeric", "numeric", "numeric", 
        "numeric", "text"), na = "NA")

LTM <- Long_term_memory_experiment_01_28_21
head(LTM)
head(LTM1)
```


## Filter and reshape data
```{r}


LTM1 <- LTM %>% 
    filter(
    Group != "random.experience", Group !="treatment.short.odd", Group !="control.odd" ) %>% #exclude bats with odd  experiences
    pivot_longer(
        !c(Bat.ID:Days.Between, Trial.Comments),
        names_to = "Playback",
        names_prefix = "Response.to.", #remove string at start of playback
        values_to = "Response.score",
        names_transform = list( 
             Playback = ~ readr::parse_factor(.x, ordered=F)), #make factor
         values_drop_na = T #drop NA values
         ) %>%
     mutate(
       Response_twitchplus = if_else(Response.score >=1, 1,0), #if response >= 1, put 1, if less, put 0 (make binary for if they at least twitched or not)
         Response_approachplus = if_else(Response.score >=2, 1,0), #if response >= 2, put 1, if less, put 0
        Response_attack =if_else(Response.score >=3, 1,0), #if response 3 put 1, otherwise 0
    )  %>%
     mutate(
          Days.Between = replace(Days.Between, Days.Between == 0, NA) #For controls bats, "timebetween" should be NA, not 0

     )





# summarize the number of bats in each group, the # of bats with each ordinal response 
#.5 scores are possible bc we average the response of control bats to sound a and b.
LTM_response <- LTM1  %>% group_by(Group, Playback) %>%
      summarise( n=n() , n_0= sum(Response.score==0),  n_0.5= sum(Response.score==0.5), n_1= sum(Response.score==1),n_1.5= sum(Response.score==1.5), n_2= sum(Response.score==2),n_2.5= sum(Response.score==2.5), n_3= sum(Response.score==3) ) 
# %>%   pivot_wider(names_from = Playback, values_from= n) 
LTM_response


#summarize # bats that at least approached and those that attacked
LTM_approach <- LTM1  %>% group_by(Group, Playback) %>%
      summarise( n=n() , n_noresp= sum(Response.score==0), n_twitchhplus= sum(Response_twitchplus ==1), n_approachplus= sum(Response_approachplus ==1), n_attack = sum(Response_attack==1)) 
LTM_response
LTM_approach
#View(LTM_approach)


```

###Comparison: If we conservatively calculate "primary" as naive bat's highest score to either A or B, rather than their mean score, does that change the results? 

```{r}
# add a column where "primary" is calculated for naive bats by taking their highest response to A or B (rather than the mean response)?



# pull only the control bats
# pull A and B
#take the higher rows for A and B
# add back
 LTM_test <- LTM1 %>% 
  mutate(Playback.max = Playback) %>% #make new column
  filter(Group %in% "control") %>% #pull control bats
  filter( Playback %in% c("A", "B")) %>% #pull A and B
  group_by(Bat.ID)  %>%
    slice(which.max(Response.score)) %>%#pull out row with higher value
 mutate(Playback.max = "Primary") #change name to primary from A or B
 
 #now combine that with treatment bat primary responses
 #not finished, still have to also select Control bat A and B
#remove A and B from treatment, remove A and B and primary from controls
 LTM_playbackmax <- LTM1 %>%
  mutate(Playback.max = Playback) %>%
 filter( !Playback %in% c("A", "B"))  %>% droplevels.data.frame() %>%
  filter(Group == "treatment" | Group == "control" & Playback != "Primary") %>%  #keep all treatment values and remove control values with Primary
   rbind(LTM_test) %>% #add back in the new computation for primary
   select(-Playback) %>%
   arrange(Group,Bat.ID, Playback.max)
 

```


## Do control bats respond differently to the different playbacks?
### Did control bats approach any of the treatments more than others?
### did they attack any of the treatments more than others?


First test strategy is a Cochran's test with a permutation approach. I'm using a packaged function, and one annoying thing is that they don't say how many permutations it runs. No way to change defaults. 
```{r, eval = FALSE }
## 		blocks = bat ids, response = binary approach/ no approach, predictors = playback
## Cochran's test is like a Friedman test with binary data, and can be permuted. 
		# This uses normal approximation, can use permutations approach (citation in link)
		#cochranq.test(mat) 

#shape into individuals in rows and treatments in columns
#group by treatment or select one treatment
#select only the relevant columns

# function for cochran tests
# group = control, Treatment, etc
# response = "Response_approachplus" "Response.score" "Response.attack"

Cochran_bats <- function(group= "control", response = "Response_approachplus"){ 
 # naming the columns to pull
    A<-paste(response, "A", sep ="_")
    B<- paste(response, "B", sep ="_")
    P<- paste(response, "Primary", sep ="_")
    C<- paste(response, "Control", sep ="_")
    S<-paste(response, "Static", sep= c("_") )
   #ifelses pull the right columns (all except primary for control (primary is redundant), no static for control.partial, etc) 
    
  if(group== "control"){
    Cols<- (c(A,B,C,S))
 
  }else if (group== "control.partial"){
    Cols<- (c(A,B,C))
    
  }else{
    Cols<- (c(P,C,S))
    }
  #shape the data
  Cochran <- LTM1 %>% 
    pivot_wider(
      names_from = "Playback",
        values_from = c("Response.score", "Response_approachplus", "Response_attack"),
    )  %>% 
    filter(Group == group)  %>% 
    select(Cols) %>% 
    #run the stat
    cochranq.test() #LTM1_wider)

   list(Cochran)
}


#cochran tests 
#approach = approach or above
#T=treatment c= control, cp= control partial, Ts=treatment short
Cochran_c_approach <- Cochran_bats(group="control", response ="Response_approachplus")
Cochran_c_attack <- Cochran_bats(group="control", response ="Response_attack")
Cochran_T_approach <- Cochran_bats(group = "treatment", response ="Response_approachplus")
Cochran_T_attack <- Cochran_bats(group = "treatment", response ="Response_attack")
Cochran_Ts_approach <- Cochran_bats(group = "treatment.short", response ="Response_approachplus")
Cochran_Ts_attack <- Cochran_bats(group = "treatment.short", response ="Response_attack")
Cochran_cp_approach <- Cochran_bats(group="control.partial", response ="Response_approachplus")
Cochran_cp_attack <- Cochran_bats(group="control.partial", response ="Response_attack")

Cochran_c_approach
Cochran_c_attack
Cochran_T_approach 
Cochran_T_attack  # p=0.018
Cochran_Ts_approach 
Cochran_Ts_attack 
Cochran_cp_approach # no data bc all 0s
Cochran_cp_attack # no data bc all 0s


### separated out (redundant just for laying with the function###
  Cochran_approach_treatment <- LTM1 %>% 
    pivot_wider(
      names_from = "Playback",
        values_from = c("Response.score", "Response_approachplus", "Response_attack"),
    )  %>% 
    filter(Group == "treatment")  %>% 
    select(Response_approachplus_Primary:Response_approachplus_Static) %>% #rn adds grouping variable
    cochranq.test() #LTM1_wider)

 Cochran_approach_treatment
####################################
   #results from COchran test are similarnot v different w regular Friedman test (p=1117)
   # or a test with the full ordinal responses p= 0.731
###################################

  
```
This works, though one concerning thing is that the values change a good amount with each run for some of the treatments. 


Here's another strategy, doing a Permuted Friedman's Test on the ordinal data. 
Permutation with ordinal rather than binary data: 
HAve prefs perhaps for T, weak for ts, not for C
```{r}
set.seed(123)

Permftest_t <- LTM1 %>% 
    filter(Group == "treatment", Playback !="A",Playback != "B")  %>% droplevels() %>%
    select(Playback, Response.score) 
Permftest_t <- perm.f.test(response =Permftest$Response.score, treatment=Permftest$Playback, num.sim=20000)

Permftest_ts <- LTM1 %>% 
    filter(Group == "treatment.short", Playback !="A",Playback != "B")  %>% droplevels() %>%
    select(Playback, Response.score) 
Permftest_ts <- perm.f.test(response =Permftest_ts$Response.score, treatment=Permftest_ts$Playback, num.sim=20000)

Permftest_c <- LTM1 %>% 
    filter(Group == "control", Playback !="Primary")  %>% droplevels() %>%
    select(Playback, Response.score) 
Permftest_c <- perm.f.test(response =Permftest_c$Response.score, treatment=Permftest_c$Playback, num.sim=20000)


Permftest_t
Permftest_ts
Permftest_c
```
one more strategy, a home-grown permutation strategy


# functions for bootstrapping 95% confidence intervals around the mean -----

```{r}
# LTM tests
# Gerry Carter

# functions for bootstrapping 95% confidence intervals around the mean -----
d <- LTM2 
# get mean and 95% CI of values x via bootstrapping
boot_ci <- function(x, perms=5000, bca=F) {
  get_mean <- function(x, d) {
    return(mean(x[d]))
  } 
  x <- as.vector(na.omit(x))
  mean <- mean(x)
  if(bca){
    boot <- boot.ci(boot(data=x, 
                         statistic=get_mean, 
                         R=perms, 
                         parallel = "multicore", 
                         ncpus = 4), 
                    type="bca")
    low <- boot$bca[1,4]
    high <- boot$bca[1,5] 
  }else{
    boot <- boot.ci(boot(data=x, 
                         statistic=get_mean, 
                         R=perms, 
                         parallel = "multicore", 
                         ncpus = 4), 
                    type="perc")
    low <- boot$perc[1,4]
    high <- boot$perc[1,5] 
  }
  c(low=low,mean=mean,high=high, N=round(length(x)))
}


# get mean and 95% CI via bootstrapping of values y within grouping variable x
boot_ci2 <- function(d=d, y=d$y, x=d$x, perms=5000, bca=F){
  df <- data.frame(effect=unique(x))
  df$low <- NA
  df$mean <- NA
  df$high <- NA
  df$n.obs <- NA
  for (i in 1:nrow(df)) {
    ys <- y[which(x==df$effect[i])] #pulls out all the e.g.location prefs
    if (length(ys)>1 & var(ys)>0 ){
      b <- boot_ci(y[which(x==df$effect[i])], perms=perms, bca=bca) #resamples with replacement the mean and ci for e.g. AJs pref for location, gives back the low mean and high
      df$low[i] <- b[1]
      df$mean[i] <- b[2]
      df$high[i] <- b[3]
      df$n.obs[i] <- b[4]
    }else{
      df$low[i] <- min(ys)
      df$mean[i] <- mean(ys)
      df$high[i] <- max(ys)
      df$n.obs[i] <- length(ys)
    }
  }
  df
}

# plot permutation test results
hist_perm <- function(exp=exp, obs=obs, perms=perms, label=''){
  exp.range <- round(quantile(exp, probs= c(0.025, 0.975)),3)
  ggplot()+
    geom_histogram(aes(x=exp), color="black",fill="light blue")+
    geom_vline(aes(xintercept=obs), color="red", size=1)+
    xlab("expected values from null model")+
    ggtitle(label, subtitle = paste('obs = ',round(obs,3), ', exp = ', exp.range[1], ' to ', exp.range[2], ", Prob exp >= obs: p", ifelse(mean(exp>=obs)==0,paste("<",1/perms), paste("=",signif(mean(exp>=obs),digits=2))),", permutations=",perms, sep=""))
}
```


```{r}
# plot data by bat and all groups
LTM1 %>% 
  #filter(Group=="control") %>% 
  ggplot(aes(x=Bat.ID, y=Response.score))+
      theme(axis.text.x = element_text(angle = 90)) +
    facet_grid(rows= vars(Playback), cols= vars(Group), scales= "free")+
    geom_col(aes(fill=Playback))

#plot data by bats and main groups
LTM2 %>% 
  #filter(Group=="control") %>% 
  ggplot(aes(x=Bat.ID, y=Response.score))+
      theme(axis.text.x = element_text(angle = 90)) +
    facet_grid(rows= vars(Playback), cols= vars(Group), scales= "free")+
    geom_col(aes(fill=Playback))



```

# what are the playback preferences by group?-----

#Bootstap bat responses by batid, plot
```{r}
plot_preference <- function(OG_scores=T){
  
  # trying to make alt method where it calculates using the playback.max scale (test by checking means_control, should be 1 if using the playback max values)
      #put plot2 within function- seems to work, the only off thing is that other values for control seem to change as well subtly. No changes to conclusions though

 # control/ naives
       if(OG_scores){
    points <- 
     d %>% 
      # get group
      #filter(Group=="control") %>% 
      group_by(Bat.ID) %>% 
      mutate(pref = Response.score) %>% 
      ungroup() %>% 
      # identify trial for bootstrapping
      mutate(effect= Playback)  
 
  }else{
    points <- 
     LTM_playbackmax %>% 
      # get group
      #filter(Group=="control") %>% 
      group_by(Bat.ID) %>% 
      mutate(pref = Response.score) %>% 
      ungroup() %>% 
      # identify trial for bootstrapping
      mutate(effect= Playback.max)  
    
    
  }

    
      
#effect = Playback      
  # get means and 95% CI
  set.seed(121)
  means_control <- 
    points %>% 
    filter(Group=="control") %>%
    boot_ci2(y=.$pref, x=.$effect)
    
  
 means_treatment <- points %>% 
       filter(Group=="treatment") %>%
    boot_ci2(y=.$pref, x=.$effect)
 
 means<- rbind(means_control, means_treatment) %>% mutate(Group =c(rep("control", 3), rep("treatment",3)))  #unlist()
 # means$groupp<- factor(means$groupp)
 
 # write_csv(means, paste0("confint_", "all", format(Sys.time(), "%Y-%m-%d_%H-%M"), ".csv") )

 


# plot means, 95% CI and raw data
 
 #dodges the minor points for plotting  
  #deffect= playback (x) dodged by treatment
  #jpref = pref (y) dodged by treatment
  points = transform(points, deffect = ifelse(Group == "control", 
                                     as.numeric(effect) - .15,
                                     as.numeric(effect) + .15 ) )
 points = transform(points, deffect = ifelse(Group == "control", 
                                     jitter(as.numeric(effect) - .08, .1),
                                     jitter(as.numeric(effect) + .08, .1) ),
               jpref = jitter(pref, amount = 0) )

 
# new try, shift points using craftiness. under x variable
 #left off here, trying foolishly to make lines into two palettes around the color of the points
 #mypal <- colorRampPalette(brewer.pal(17, "'dark grey'"))
#mypal2 <- colorRampPalette(brewer.pal(17, "1b9e77"))

 (plot2 <- 
    means %>% 
    ggplot(aes(x=effect, y=mean, color= Group))+
    #facet_wrap(~Group, scales="free")+
    geom_blank(data=points, aes(x=effect, y=pref)) +
    geom_point(size=3, position = position_dodge(width = 0.3))+ #bootstrapped means
   # geom_line(data= points, aes(x=deffect, y= jpref, group= Bat.ID, color =Group),  alpha=0.2) +  #minor points individual bats
   # geom_point( data = points, aes(x= deffect, y=jpref, group=Bat.ID), size=1, alpha=0.1 )  + #minor lines individual bats 
    geom_errorbar(aes(ymin=low, ymax=high, width=.1), size=1, position = position_dodge(width = 0.3))+ #bootstrapped confidence intervals +
        scale_color_manual(values=c('dark grey','#1b9e77','#d95f02','#7570b3'), labels= c("control" = "Naïve", "treatment" = "Experienced"), name = "Treatment") +

    # geom_blank(data=points, aes(x=effect, y=pref)) +
    
   
    
   
   scale_x_discrete(labels= c("Primary" = "Trained", "Control"= "Extinguished", "Static" ="Control" )) +
 
     ylab("Response scores")+
      xlab("")+
   
    theme_cowplot(8)+
   
     scale_y_continuous(labels= c("0" = "No response (0)", "1" = "Ear twitches (1)",
                              "2" = "Approach (2)", "3"= "Attack (3)")) 
 
 )
 
 
 list(means,plot2)
 
}
plot_preference(OG_scores = FALSE)
plot_preference(OG_scores = TRUE)

plot2


 
 #ggsave("Responses_mean_bytreatment_nolines.pdf", units = "mm",  height = 54, width = 84) # width = 84,, , units= "mm" )
 #ggsave("Responses_mean_bytreatment_nolines.pdf", width = )
```
 
```{r}
 #Feb 22, trying to figure out where "points" is made, seems to be in a function, unclear when it is called, why it won't update. Switching to d- precurser of "points" for this plot. points just has the bootstrapped estimates.

 
   
 plot3 <- 
     d %>% 
     ggplot(aes(x=Playback, y=Response.score, color= Group))+
     facet_wrap(~ Days.Between + Bat.ID, 
               # ncol = 4, # leave out to have default gridding
                strip.position = "top") + #facet by time in wild (helps to order plots)
     geom_point( position = position_dodge(width = 0.3))+ #bootstrapped means
    # geom_errorbar(aes(ymin=low, ymax=high, width=.1), size=1, position = position_dodge(width = 0.3))+ #bootstrapped confidence intervals +
         scale_color_manual(values=c('dark grey','#1b9e77','#d95f02','#7570b3'), labels= c("control" = "Naïve", "treatment" = "Experienced"), name = "Treatment") +
  scale_y_continuous(labels= c("0" = "No response (0)", "1" = "Ear twitches (1)",
                              "2" = "Approach (2)", "3"= "Attack (3)"), expand = expand_scale(add = .5) ) + #adds padding at top and bottom of y axis
    # 
    #  geom_blank(data=points, aes(x=effect, y=pref)) +
    
    #geom_point( data = points, aes(x= deffect, y=jpref, group=Bat.ID), size=1, alpha=0.1 )  +
    
   geom_line(data= d, aes(x=Playback, y= Response.score, group= Bat.ID, color =Group),  alpha=0.5) + 
   scale_x_discrete(labels= c("Primary" = "T", "Control"= "E", "Static" ="C" )) +
 
     ylab("Highest Response")+
      xlab("")+
   
   geom_text(aes(label = Days.Between, x =  0.45, y = 0, vjust = 0.4, hjust = "left",),  show.legend = FALSE)+ 
    #theme_cowplot(8)+
     #theme_minimal() +
   theme(
    strip.text.x = element_blank() ,
   # panel.grid = element_blank(), 
    panel.border = element_rect(color ="black", fill = NA), #element_blank(),
    #panel.grid.major.y = element_line(color = "black"),
    #plot.background = element_blank(),
    #axis.ticks.x = element_line(color = "black"),
    
    legend.position = "top" )   #legend on top
   
     
 
plot3
#ggsave("Responses_bybat_3.jpg", width= 6, height = 4) #6 x 4.5 looks okay



 
```

Same as plot 3, but trying to see if it works to have A, B, E, and C
```{r}
 ## make dataframe with both A and B, and not Primary
LTM_AB <- LTM1 %>% 
  filter(Group %in% c("control", "treatment")) %>%
  filter( !Playback %in% "Primary")  %>% droplevels.data.frame()
 
   
 plot4 <- 
     LTM_AB %>% 
     ggplot(aes(x=Playback, y=Response.score, color= Group))+
     facet_wrap(~ Days.Between + Bat.ID, 
               # ncol = 4, # leave out to have default gridding
                strip.position = "top") + #facet by time in wild (helps to order plots)
     geom_point( position = position_dodge(width = 0.3))+ #bootstrapped means
    # geom_errorbar(aes(ymin=low, ymax=high, width=.1), size=1, position = position_dodge(width = 0.3))+ #bootstrapped confidence intervals +
         scale_color_manual(values=c('dark grey','#1b9e77','#d95f02','#7570b3'), labels= c("control" = "Naïve", "treatment" = "Experienced"), name = "Treatment") +
  scale_y_continuous(labels= c("0" = "No response (0)", "1" = "Ear twitches (1)",
                              "2" = "Approach (2)", "3"= "Attack (3)"), expand = expand_scale(add = .5) ) + #adds padding at top and bottom of y axis
    # 
    #  geom_blank(data=points, aes(x=effect, y=pref)) +
    
    #geom_point( data = points, aes(x= deffect, y=jpref, group=Bat.ID), size=1, alpha=0.1 )  +
    
   geom_line(data= LTM_AB, aes(x=Playback, y= Response.score, group= Bat.ID, color =Group),  alpha=0.5) + 
   scale_x_discrete(labels= c("A" = "A", "B" = "B", "Control"= "E", "Static" ="C" )) +
 
     ylab("Highest Response")+
      xlab("")+
   
   geom_text(aes(label = Days.Between, x =  0.45, y = 0, vjust = 0.4, hjust = "left",),  show.legend = FALSE)+ 
    #theme_cowplot(8)+
     #theme_minimal() +
   theme(
    strip.text.x = element_blank() ,
   # panel.grid = element_blank(), 
    panel.border = element_rect(color ="black", fill = NA), #element_blank(),
    panel.grid.minor = element_blank(),
    #plot.background = element_blank(),
    #axis.ticks.x = element_line(color = "black"),
    
    legend.position = "top" )   #legend on top
   
     
 
plot4
#ggsave("ResponsesAB_bybat.jpg", width= 5, height = 4) #6 x 4.5 looks okay



 
```
```{r}
 ## plot of all bats responses, faceted out, but as a barchart


##  add small value to "0" bars for plotting (make 0's visible)
LTM_plotting <- LTM_AB %>% mutate(Response.score, Plotting.scores = if_else(Response.score == "0", .1, Response.score ))
   


 plot5 <- 
     LTM_plotting %>% 
     ggplot(aes(x=Playback, y=Plotting.scores,  fill = Group))+
     facet_wrap(~ Days.Between + Bat.ID, 
               # ncol = 4, # leave out to have default gridding
                strip.position = "top") + #facet by time in wild (helps to order plots)
     geom_bar( position = position_dodge(width = 0.3), stat = "identity")+ #bootstrapped means
    # geom_errorbar(aes(ymin=low, ymax=high, width=.1), size=1, position = position_dodge(width = 0.3))+ #bootstrapped confidence intervals +
         scale_fill_manual(values=c('dark grey','#1b9e77','#d95f02','#7570b3'), labels= c("control" = "Naïve", "treatment" = "Experienced"), name = "Treatment") +
  scale_y_continuous(labels= c("0" = "No response (0)", "1" = "Ear twitches (1)",
                              "2" = "Approach (2)", "3"= "Attack (3)") ) +#, expand = expand_scale(add = .5) ) + #adds padding at top and bottom of y axis
    # 
    #  geom_blank(data=points, aes(x=effect, y=pref)) +
    
    #geom_point( data = points, aes(x= deffect, y=jpref, group=Bat.ID), size=1, alpha=0.1 )  +
    
   #geom_line(data= LTM_AB, aes(x=Playback, y= Plotting.scores, group= Bat.ID, color =Group),  alpha=0.5) + 
   scale_x_discrete(labels= c("A" = "A", "B" = "B", "Control"= "E", "Static" ="C" )) +
 
     ylab("Highest Response")+
      xlab("")+
   
   #geom_text(aes(label = Days.Between, x =  0.45, y = 0, vjust = 0.4, hjust = "left",),  show.legend = FALSE)+ 
    #theme_cowplot(8)+
   #  theme_minimal() +
   theme(
    strip.text.x = element_blank() ,
    #panel.grid = element_blank(), 
    panel.border = element_rect(color ="black", fill = NA), 
    #panel.grid.major.y = element_line(color = "gray"),
    panel.grid.minor = element_blank(),
    # plot.background = element_blank(),
    axis.ticks.x = element_line(color = "black"),
    axis.ticks.y = element_line(color = "black"),
    panel.spacing = unit(10, "pt"),
    legend.position = "top" )   #legend on top
   
     
 
plot5
#ggsave("ResponsesAB_bybat_barplot.jpg", width= 5, height = 4) #6 x 4.5 looks okay



 
```





# make function to plot data
(old- does group one by one)
```{r, eval=F}
plot_preference <- function(group= "control", OG_scores=T){
  
  # alt method is to center  by response.score per bat to remove effect of some bats having higher scores in general than others. this doesn't necessarily make sense...
  # other method is to use proportions to remove effect of total number of choices
  if(OG_scores){
    points <- 
     d %>% 
      # get group
      filter(Group==group) %>% 
      group_by(Bat.ID) %>% 
      mutate(pref = Response.score) %>% 
      ungroup() %>% 
      # identify trial for bootstrapping
      mutate(effect= Playback)  
 
  }else{
    points <- 
     d %>% 
      # get group
      filter(Group==group) %>% 
      # center counts by bat
      group_by(Bat.ID) %>% 
      mutate(pref = Response.score - mean(Response.score)) %>% 
      ungroup() %>% 
      # identify trial for bootstrapping
      mutate(effect= Playback)  
    
    
  }

      
      
#effect = Playback      
  # get means and 95% CI
  set.seed(121)
  means <- 
    points %>% 
    boot_ci2(y=.$pref, x=.$effect)
    
  
  # write_csv(means, paste0("confint_", ifelse(group=="control","naive","experienced")
  #             , format(Sys.time(), "%Y-%m-%d_%H-%M")
  #             , ".csv") )

  # plot means, 95% CI and raw data
  plot <- 
    means %>% 
    ggplot(aes(x=effect, y=mean, color=effect))+
    #facet_wrap(~Group, scales="free")+
    geom_point(size=3)+
    geom_jitter(data= points, aes(y= pref), size=1, alpha=0.5, width=0.1, height=0)+
    geom_errorbar(aes(ymin=low, ymax=high, width=.1), size=1)+
    #geom_hline(yintercept = ifelse(OG_scores, NA, 0), color= "dark grey")+
    ylab(ifelse(OG_scores,
                "Response scores",
                "relative response scores (observed - expected)"))+
    xlab("Sounds")+
    scale_x_discrete(labels= c("Primary" = "Trained", "Control"= "Extinguished", "Static" ="Control" )) +
    ggtitle(ifelse(group=="control", expression(paste("Naive ", italic("T. cirhossus"))), 
                                  expression(paste("Experienced ", italic("T. cirrhosus")))))+
    theme_cowplot()+
    scale_color_manual(values=c('#1b9e77','dark grey','#d95f02','#7570b3'))
  
 ggsave(paste0("plot_", ifelse(group=="control","naive","experienced")
              , format(Sys.time(), "%Y-%m-%d_%H-%M")
              , ".pdf"))
 
 
 list(means,plot)
}

# get results----
# use that function to plot preferences for naive bats
# table shows summary data that is plotted
(naive.results <- plot_preference(group="control", OG_scores = T))

# use that function plot preferences for treatment bats
(experienced.results <- plot_preference(group="treatment", OG_scores = T))
means


```


Make plots with control and treatment bats on same plot. 
Prep data
```{r}
#pull 95% confidence intervals and combine them 
naive.results<- naive.results[[1]] %>% mutate(group="control")
experienced.results <- experienced.results[[1]] %>% mutate(group="treatment")
cbind(naive.results, experienced.results)

results_confint <-  rbind(naive.results, experienced.results) %>% mutate(group=c(rep("control",3), rep("treatment", 3)))
```

#make plots
```{r, eval= FALSE}
plot1 <- 
    results_confint %>% 
    ggplot(aes(x=effect, y=mean, color=group))+
    #facet_wrap(~Group, scales="free")+
    geom_point(size=3)+
    geom_jitter(data= points, aes(y= pref), size=1, alpha=0.5, width=0.1, height=0)+
    geom_errorbar(aes(ymin=low, ymax=high, width=.1), size=1)+
    #geom_hline(yintercept = ifelse(OG_scores, NA, 0), color= "dark grey")+
    ylab(ifelse(OG_scores,
                "Response scores",
                "relative response scores (observed - expected)"))+
    xlab("")+
  scale_x_discrete(labels= c("Primary" = "Trained", "Control"= "Extinguished", "Static" ="Control" )) +
    ggtitle(ifelse(group=="control", expression(paste("Naive ", italic("T. cirhossus"))), 
                                  expression(paste("Experienced ", italic("T. cirrhosus")))))+
    theme_cowplot()+
    scale_color_manual(values=c('#1b9e77','dark grey','#d95f02','#7570b3'))
  
 # ggsave(paste0("plot_", ifelse(group=="control","naive","experienced")
 #              , format(Sys.time(), "%Y-%m-%d_%H-%M")
 #              , ".pdf"))
 # 

```





## Did control bats respond differently than treatment bats?

Permutation approach- use difference between groups. One question is whether I should use median or mean to compare between groups, since I'm using ordinal data. Perhaps ok to use mean if I'm careful about interpretation. 

Gerry code for plotting permutation test results
```{r}
#plot permutation test results
hist_perm <- function(exp=exp, obs=obs, perms=perms, label=''){
  exp.range <- round(quantile(exp, probs= c(0.025, 0.975)),3)
  ggplot()+
    geom_histogram(aes(x=exp), color="black",fill="light blue")+
    geom_vline(aes(xintercept=obs), color="red", size=1)+
    xlab("expected values from null model")+
    ggtitle(label, subtitle = paste('obs = ',round(obs,3), ', exp = ', exp.range[1], ' to ', exp.range[2], ", Prob exp >= obs: p", ifelse(mean(exp>=obs)==0,paste("<",1/perms), paste("=",signif(mean(exp>=obs),digits=2))),", permutations=",perms, sep=""))
  

}
```

```{r}
# Are there Treatment differences?-----
# use permutation test to compare treatments (using null model that randomizes treatment group while controlling for everything else)


# get difference between groups in median response to each playback
# store as vector of differences

#only 2 groups, relevant playbacks
LTM2 <- LTM1 %>% 
  filter(Group %in% c("control", "treatment")) %>%
  filter( !Playback %in% c( "A","B"))  %>% droplevels.data.frame()
  

obs<- LTM2 %>% 
  ungroup() %>%
  group_by(Group, Playback) %>% 
  summarize(response= mean(Response.score)) %>% 
  pivot_wider(names_from = Group, values_from= response) %>% 
  mutate(diff= treatment-control) %>% 
  arrange(Playback) %>% 
  pull(diff)

# numbers are T-C differences for:
# primary control static
# positive number means treatments had higher score
# we cannot interpret these without the null model of what to expect by chance!


obs

# get expected difference between treatment if bat choices were random across treatments 

# how many permutations?
perms <- 5000

# store results in matrix
exp <- matrix(NA, ncol=length(obs), nrow= perms) 


 namesgroup<- LTM2 %>%
    ungroup() %>%
    distinct(Bat.ID, .keep_all=T) %>%
    select(Bat.ID, Group)
  
# for loop to get expected results
  for(i in 1:perms) {
 
 #pull out unique ids, randomly reassign group to them, add back 
 Groupperm <- namesgroup %>% mutate(permgrp = sample(Group)) %>% select(Bat.ID, permgrp)
  LTM_perm <- LTM2 %>% left_join(Groupperm)

  # get same number as before, but with permuted group values
  exp[i,] <- 
    LTM_perm %>% 
    group_by(permgrp, Playback) %>% 
    summarize(response= mean(Response.score), .groups= 'drop') %>% #  # apparently drop is needed just bc new version of tidyverse gives a random warning, this prevents that  
  pivot_wider(names_from = permgrp, values_from= response) %>% 
  mutate(diff= treatment-control) %>% 
  arrange(Playback) %>% 
  pull(diff)
  } 
  
# get p-value for species difference for primary (column 1)
hist_perm(exp= exp[,1], obs= obs[1], perms=perms) 
#ggsave("histogram_permutations_experienced_v_naive_trained.jpg")
# get p-value for species difference for control/ extinguished (column 2)
hist_perm(exp= exp[,2], obs= obs[2], perms=perms) 
#ggsave("histogram_permutations_experienced_v_naive_extinguished.jpg")
# get p-value for species difference for static (column 3)
hist_perm(exp= exp[,3], obs= obs[3], perms=perms)
#ggsave("histogram_permutations_experienced_v_naive_staticcontrol.jpg")

###
  ###
 # p value for primary/ trained: 
sum((exp[,1] >= obs[1])/perms) #one tailed #0
sum((abs(exp[,1]) >= abs(obs[1]))/perms) #two-tailed #0

## p value for control/ extinguished
sum((exp[,2] >= obs[2])/perms) #0
sum((abs(exp[,2]) >= abs(obs[2]))/perms) #two-tailed #0
 
 ## p value for static/ control
 sum((exp[,1] >= obs[3])/perms) #0.107
 sum((abs(exp[,3]) >= abs(obs[3]))/perms) #two-tailed 0.2144
  
```

Difference between experienced bat response to Trained and extinguished? 
```{r}
# Did experienced bats respond differently to the different treatments?-----
# use permutation test to compare treatments (using null model that randomizes treatment group while controlling for everything else)


# get difference between treatments in median response to each playback
# store as vector of differences

#only 1 group, relevant playbacks
LTM3 <- LTM1 %>% 
  filter(Group %in% c( "treatment")) %>%
  filter( !Playback %in% c( "A","B"))  %>% droplevels.data.frame()
  

obs<- LTM3 %>% 
  ungroup() %>%
  group_by(Playback) %>% 
  summarize(response= mean(Response.score)) %>% 
  pivot_wider(names_from = Playback, values_from= response) %>% 
  mutate(diff= Primary-Static) %>% 
  pull(diff)

# number is difference for:
# primary and static
# positive number means primary had higher score
# we cannot interpret these without the null model of what to expect by chance!


obs

# get expected difference between treatment if bat choices were random across treatments 

# how many permutations?
perms <- 5000

# store results in matrix
exp <- matrix(NA, ncol=length(obs), nrow= perms) 

##stopped here, I want to pull out distinct bats, randomly reassign the playback, add them back
# #pull out distinct names (changed Group to Playback)
#   namesgroup<- LTM3 %>%
#     ungroup() %>%
#     distinct(Bat.ID, .keep_all=T) %>%
#     select(Bat.ID, Group)
  
# for loop to get expected results
  for (i in 1:perms){
  
  exp[i,] <- 
    LTM3 %>% 
    # re-assign visits to different cues within each trial 
    group_by(Bat.ID) %>% 
    mutate(Response.score = Response.score[sample(row_number())]) %>%  
    
  ungroup() %>%
  group_by(Playback) %>% 
  summarize(response= mean(Response.score)) %>% 
  pivot_wider(names_from = Playback, values_from= response) %>% 
  mutate(diff= Primary-Static) %>% 
  pull(diff)
   #beep(12)  
} 
# get p-value for difference in experienced bat response between trained and static: 
hist_perm(exp= exp[,1], obs= obs[1], perms=perms)




###
  ###
 # p value for difference in experienced bat response to trained and static: 
sum((exp[,1] >= obs[1])/perms) #one tailed
sum((abs(exp[,1]) >= abs(obs[1]))/perms) #two-tailed

#best to use two-tailed, bc would be interesting/ possible, if odd for control bats to have higher responses than experienced

  
```

```{r}
# Did experienced bats respond differently to the primary vs extinguished treatments?-----
# use permutation test to compare treatments (using null model that randomizes treatment group while controlling for everything else)


# get difference between treatments in median response to each playback
# store as vector of differences

#only 1 group, relevant playbacks
LTM3 <- LTM1 %>% 
  filter(Group %in% c( "treatment")) %>%
  filter( !Playback %in% c( "A","B"))  %>% droplevels.data.frame()
  

obs<- LTM3 %>% 
  ungroup() %>%
  group_by(Playback) %>% 
  summarize(response= mean(Response.score)) %>% 
  pivot_wider(names_from = Playback, values_from= response) %>% 
  mutate(diff= Primary-Control) %>% 
  pull(diff)

# number is difference for:
# primary and static
# positive number means primary had higher score
# we cannot interpret these without the null model of what to expect by chance!


obs

# get expected difference between treatment if bat choices were random across treatments 

# how many permutations?
perms <- 5000

# store results in matrix
exp <- matrix(NA, ncol=length(obs), nrow= perms) 

##stopped here, I want to pull out distinct bats, randomly reassign the playback, add them back
# #pull out distinct names (changed Group to Playback)
#   namesgroup<- LTM3 %>%
#     ungroup() %>%
#     distinct(Bat.ID, .keep_all=T) %>%
#     select(Bat.ID, Group)
  
# for loop to get expected results
  for (i in 1:perms){
  
  exp[i,] <- 
    LTM3 %>% 
    # re-assign visits to different cues within each trial 
    group_by(Bat.ID) %>% 
    mutate(Response.score = Response.score[sample(row_number())]) %>%  
    
  ungroup() %>%
  group_by(Playback) %>% 
  summarize(response= mean(Response.score)) %>% 
  pivot_wider(names_from = Playback, values_from= response) %>% 
  mutate(diff= Primary-Control) %>% 
  pull(diff)
   #beep(12)  
} 
# get p-value for difference in experienced bat response between trained and static: 
hist_perm(exp= exp[,1], obs= obs[1], perms=perms)




###
  ###
 # p value for difference in experienced bat response to trained and static: 
sum((exp[,1] >= obs[1])/perms) #one tailed
sum((abs(exp[,1]) >= abs(obs[1]))/perms) #two-tailed

#best to use two-tailed, bc would be interesting/ possible, if odd, for experienced bats to have higher responses to control than experienced

  
```
Playing with trying to pull 2 things at the same time. Primary- Static and Primary- Control. Not finished

```{r, eval = FALSE}
# Did experienced bats respond differently to the different treatments?-----
# use permutation test to compare treatments (using null model that randomizes treatment group while controlling for everything else)
#not working yet, pull doens't pull in right format. 

# get difference between treatments in median response to each playback
# store as vector of differences

#only 1 group, relevant playbacks
LTM3 <- LTM1 %>% 
  filter(Group %in% c( "treatment")) %>%
  filter( !Playback %in% c( "A","B"))  %>% droplevels.data.frame()
  

obs<- LTM3 %>% 
  ungroup() %>%
  group_by(Playback) %>% 
  summarize(response= mean(Response.score)) %>% 
  pivot_wider(names_from = Playback, values_from= response) %>% 
  mutate(diffPS= Primary-Static, diffPC = Primary-Control) %>% 
  pull(diffPS,diffPC)

# number is difference for:
# primary and static
# positive number means primary had higher score
# we cannot interpret these without the null model of what to expect by chance!


obs

# get expected difference between treatment if bat choices were random across treatments 

# how many permutations?
perms <- 100

# store results in matrix
exp <- matrix(NA, ncol=length(obs), nrow= perms) 

##stopped here, I want to pull out distinct bats, randomly reassign the playback, add them back
# #pull out distinct names (changed Group to Playback)
#   namesgroup<- LTM3 %>%
#     ungroup() %>%
#     distinct(Bat.ID, .keep_all=T) %>%
#     select(Bat.ID, Group)
  
# for loop to get expected results
  for (i in 1:perms){
  
  exp[i,] <- 
    LTM3 %>% 
    # re-assign visits to different cues within each trial 
    group_by(Bat.ID) %>% 
    mutate(Response.score = Response.score[sample(row_number())]) %>%  
    
  ungroup() %>%
  group_by(Playback) %>% 
  summarize(response= mean(Response.score)) %>% 
  pivot_wider(names_from = Playback, values_from= response) %>% 
  mutate(diffPS= Primary-Static, diffPC = Primary-Control) %>% 
  pull(diffPS, diffPC)
   #beep(12)  
} 
# get p-value for difference in experienced bat response between trained and static: 
hist_perm(exp= exp[,1], obs= obs[1], perms=perms)

hist_perm(exp= exp[,2], obs= obs[2], perms=perms)




###
  ###
 # p value for difference in experienced bat response to trained and static: 
sum((exp[,1] >= obs[1])/perms) #one tailed
sum((abs(exp[,1]) >= abs(obs[1]))/perms) #two-tailed

#best to use two-tailed, bc would be interesting/ possible, if odd for control bats to have higher responses than experienced

  
```
############################################################################################
# Test, same stats, put with conservative value for naive bats response to primary/ trained

##Summarize any differences between the two methods. Other values should be same, REsponse scores for naive primary should be slightly sifferent.
```{r}


#comparing naive trained responses with two methods side by side. 

#pulling out Response.scores for controls to Primary with both methods
LTM_compare <-LTM_playbackmax %>% 
  filter(Group=="control", Playback.max =="Primary") %>% 
  select(Response.score)%>% 
  rename(Response.score.max = Response.score) %>% 
  cbind(LTM2 %>% filter(Group=="control", Playback =="Primary") %>% 
  select(Response.score) ) 
LTM_compare

#Summarize differences
mean_compare <- LTM_compare %>%
  summarize(mean.response.score.max = mean(Response.score.max), 
            mean.response.score = mean(Response.score), 
            difference = mean(Response.score.max-mean(Response.score)) )
mean_compare
#Difference in the two metrics is 0.205
```


```{r}
# Are there Treatment differences?-----
# use permutation test to compare treatments (using null model that randomizes treatment group while controlling for everything else)


# get difference between groups in median response to each playback
# store as vector of differences

#only 2 groups, relevant playbacks


obs<- LTM_playbackmax %>% 
  ungroup() %>%
  group_by(Group, Playback.max) %>% 
  summarize(response= mean(Response.score)) %>% 
  pivot_wider(names_from = Group, values_from= response) %>% 
  mutate(diff= treatment-control) %>% 
  arrange(Playback.max) %>% 
  pull(diff)

# numbers are T-C differences for:
# primary control static
# positive number means treatments had higher score
# we cannot interpret these without the null model of what to expect by chance!


obs

# get expected difference between treatment if bat choices were random across treatments 

# how many permutations?
perms <- 5000

# store results in matrix
exp <- matrix(NA, ncol=length(obs), nrow= perms) 


 namesgroup<- LTM_playbackmax %>%
    ungroup() %>%
    distinct(Bat.ID, .keep_all=T) %>%
    select(Bat.ID, Group)
  
# for loop to get expected results
  for(i in 1:perms) {
 
 #pull out unique ids, randomly reassign group to them, add back 
 Groupperm <- namesgroup %>% mutate(permgrp = sample(Group)) %>% select(Bat.ID, permgrp)
  LTM_perm <- LTM_playbackmax %>% left_join(Groupperm)

  # get same number as before, but with permuted group values
  exp[i,] <- 
    LTM_perm %>% 
    group_by(permgrp, Playback.max) %>% 
    summarize(response= mean(Response.score), .groups= 'drop') %>% #  # apparently drop is needed just bc new version of tidyverse gives a random warning, this prevents that  
  pivot_wider(names_from = permgrp, values_from= response) %>% 
  mutate(diff= treatment-control) %>% 
  arrange(Playback.max) %>% 
  pull(diff)
  } 
  
# get p-value for species difference for primary (column 1)
hist_perm(exp= exp[,1], obs= obs[1], perms=perms) 
#ggsave("histogram_permutations_experienced_v_naive_trained.jpg")
# get p-value for species difference for control/ extinguished (column 2)
hist_perm(exp= exp[,2], obs= obs[2], perms=perms) 
#ggsave("histogram_permutations_experienced_v_naive_extinguished.jpg")
# get p-value for species difference for static (column 3)
hist_perm(exp= exp[,3], obs= obs[3], perms=perms)
#ggsave("histogram_permutations_experienced_v_naive_staticcontrol.jpg")

###
  ###
 # p value for primary/ trained: 
sum((exp[,1] >= obs[1])/perms) #one tailed #0
sum((abs(exp[,1]) >= abs(obs[1]))/perms) #two-tailed #0 # still the same result

## p value for control/ extinguished
sum((exp[,2] >= obs[2])/perms) #0
sum((abs(exp[,2]) >= abs(obs[2]))/perms) #two-tailed #0
 
 ## p value for static/ control
 sum((exp[,1] >= obs[3])/perms) #0.107
 sum((abs(exp[,3]) >= abs(obs[3]))/perms) #two-tailed 0.2144
  
```





############################################################################################

## Timeline data isolated and basic timline for Experienced bats
```{r}
# Table of time and response
(timeline <- LTM %>% 
  filter(Group=="treatment") %>% 
  mutate(one.plot= 1, wild.days = Date.Tested - Date.First.Released) %>%
  select(Bat.ID, Date.Tested, Date.First.Released, wild.days, one.plot, Response.to.Primary:Response.to.Static) %>%
  arrange(wild.days) %>% mutate( wild.years = time_length(wild.days, unit = "year")))
#write.csv(timeline, "timeline.csv")

# timeline of experienced bats
timeline.plot <- ggplot(timeline, aes(y=one.plot, x=wild.days)) +
    geom_point() +
    theme_cowplot(12)  +
    theme(axis.line.y = element_blank(), axis.text.y =element_blank(), axis.title.y= element_blank(), axis.ticks.y=element_blank() ) + #remove y axis
    scale_x_continuous(limits=c(0, 1600),  breaks=seq(0,1600,200)) +
      scale_y_continuous(limits=c(0, 10)) +
    xlab("")

#ggsave("timeline.axis.2.jpg", width = 6.5, height=1, units = "in")
```

## Timeline heat plot for experienced bats
```{r}
#heatmap of experienced bats responses with time
timeline_heat<- timeline %>% pivot_longer(
        !c(Bat.ID:one.plot, wild.years),
        names_to = "Playback",
        names_prefix = "Response.to.", #remove string at start of playback
        values_to = "Response.score",
        names_transform = list( 
             Playback = ~ readr::parse_factor(.x, ordered=F)), #make factor
         values_drop_na = T #drop NA values
         ) %>%
          ggplot(aes(y= Playback, x= as.factor(wild.days), fill= Response.score))+
          geom_tile(color="white", alpha = 50) +
          scale_fill_gradientn(name = "Response", colours=c("light gray","#893101"), labels= c("0" = "NR", "1" = "Ear twitches", "2" = "Approach", "3"= "Attack")) +
          ylab("Sounds") +
          xlab("Days between release and retesting") +
          scale_y_discrete(labels= c("Primary" = "Trained", "Control"= "Extinguished", "Static" ="Control" )) +
    theme_cowplot(9) +
  theme(axis.text.y = element_text(angle = 0)) +
  #make legend smaller
   
  #theme(panel.grid= element_line())
 timeline_heat
# pdf("timeline_heat.pdf",  width = 3.307, height = 3.307)
# print(timeline_heat)
# dev.off()
# 
#ggsave(paste0("time_responseplot",  format(Sys.time(), "%Y-%m-%d"), ".pdf"), width = 174,  height = 20, units= "mm")
#ggsave(paste0("time_responseplot",  format(Sys.time(), "%Y-%m-%d_%H-%M"), ".jpg"),width = 84,  height = 84, units= "mm")
#ggsave(paste0("time_responseplot",  format(Sys.time(), "%Y-%m-%d_%H-%M"), ".eps"),width = 84,  height = 84, units= "mm")


#scale_color_manual(values=c('dark grey','#1b9e77','#d95f02','#7570b3') #9e1b42 
 
```

## Naive bat heatplot
```{r}
 # NAive bat sumamry: 
 Naive_summary <- LTM %>% 
  filter(Group=="control") %>% 
  select(Bat.ID, Date.Tested, Response.to.A, Response.to.B, Response.to.Control, Response.to.Static) %>%
   droplevels()%>%
  arrange(Date.Tested)
 
 Naive_heat<- Naive_summary %>% pivot_longer(
        !c(Bat.ID:Date.Tested),
        names_to = "Playback",
        names_prefix = "Response.to.", #remove string at start of playback
        values_to = "Response.score",
        names_transform = list( 
             Playback = ~ readr::parse_factor(.x, ordered=F)), #make factor
         values_drop_na = T,
         ) 
 # Naive_heat$Response.score <-  factor( Naive_heat$Response.score, levels = c(0:3), ordered= T)
 
 Naive_heat_plot <- Naive_heat %>%
   ggplot(aes(y= as.factor(Bat.ID), x= Playback, fill= Response.score))+
          geom_raster() +
           scale_fill_gradientn(name = "Response", limits = c(0,3), colours=c("dark gray","#6c122d"), labels= c("0" = "NR", "1" = "Ear twitches", "2" = "Approach", "3"= "Attack")) + #limits keeps the same gradient as the other plot, despite no 3s here
          xlab("Sounds") +
          ylab("Bats") +
          scale_x_discrete(labels= c("A" = "Trained A", "B"= "Trained B", "Control"= "Extinguished", "Static" ="Control" )) +
    theme_cowplot(9) 
   
  #theme(panel.grid= element_line())
 Naive_heat_plot
 #ggsave("naive_heat_plot.jpg")
 
```

## PLaying around with analysing time (probably not enough data)
```{r}
# ## look at time formally? probably not worth it
# # response.score ~ treatment*time
# library(ordinal)
# dd<- timeline %>% pivot_longer(
#         !c(Bat.ID:one.plot, wild.years),
#         names_to = "Playback",
#         names_prefix = "Response.to.", #remove string at start of playback
#         values_to = "Response.score",
#         names_transform = list( 
#              Playback = ~ readr::parse_factor(.x, ordered=F)), #make factor
#          values_drop_na = T #drop NA values
#          )
# dd$Bat.ID <- as.factor(dd$Bat.ID)
#  clmm2(as.factor(Response.score) ~Playback * wild.days, random= dd$Bat.ID, data = dd, Hess = TRUE)
#  
# summary(lm(Response.score ~ wild.days,  data = dd))
# 
# head(timeline)

```



## Old code
### fix data and run friedman's test
### So, need to make new timeline graphic
### Need to update graphs
### Maybe need to throw in friedman's test

##
# # bats that flew towards the speaker in response to their #primary #stimulus, or either A or B,  including only long ltm bats, if can only use 10 Controls
# 
# fisher.test(rbind(c(1,9),c(6,0)), alternative="less")
# 
# 
# # bats that flew towards the speaker in response to the #control# stimulus, including only long ltm bats,  if can only use 10 Controls
# 
# fisher.test(rbind(c(1,9),c(5,1)), alternative="less")
# 
# # bats that flew towards the speaker in response to the #static# stimulus, including only long LTM treatment bats, 10 controls
# 
# fisher.test(rbind(c(1,9),c(1,5)), alternative="less")

